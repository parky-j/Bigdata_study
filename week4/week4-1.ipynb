{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1244e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "myConf=pyspark.SparkConf()\n",
    "spark = pyspark.sql.SparkSession.builder\\\n",
    "    .master(\"local\")\\\n",
    "    .appName(\"myApp\")\\\n",
    "    .config(conf=myConf)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e40eb27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "popRddBin = spark.sparkContext.binaryFiles(os.path.join(\"data\",\"경기도 의정부시_인구현황_20210910.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50d51e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "_my = popRddBin.map(lambda x :x[1].decode('euc-kr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7cb9408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['행정기관,인구수(계),인구수(남),인구수(여),구성비(계),구성비(남),구성비(여),성비,세대수,세대당인구,관리기관명,관리부서명,부서전화번호,데이터기준일자\\r\\n의정부1동,32292,16538,15754,6.97,3.57,3.4,104.98,19998,1.61,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n의정부2동,31380,15608,15772,6.77,3.37,3.4,98.96,16410,1.91,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n호원1동,36124,17595,18529,7.8,3.8,4,94.96,15653,2.31,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n호원2동,34957,16923,18034,7.54,3.65,3.89,93.84,13683,2.55,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n장암동,20314,9714,10600,4.38,2.1,2.29,91.64,8604,2.36,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n신곡1동,43159,21205,21954,9.31,4.58,4.74,96.59,17990,2.4,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n신곡2동,47852,23232,24620,10.33,5.01,5.31,94.36,19218,2.49,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n송산1동,42817,21276,21541,9.24,4.59,4.65,98.77,18811,2.28,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n송산2동,33565,16601,16964,7.24,3.58,3.66,97.86,13216,2.54,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n송산3동,46892,22772,24120,10.12,4.91,5.21,94.41,17926,2.62,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n자금동,27087,13270,13817,5.85,2.86,2.98,96.04,11868,2.28,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n가능동,25990,12974,13016,5.61,2.8,2.81,99.68,12492,2.08,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n흥선동,19176,9769,9407,4.14,2.11,2.03,103.85,9380,2.04,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n녹양동,21768,10872,10896,4.7,2.35,2.35,99.78,9556,2.28,의정부시,민원여권과,031-828-2466,2021-09-10\\r\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_my.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25147976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'의정부1동,32292,16538,15754,6.97,3.57,3.4,104.98,19998,1.61,의정부시,민원여권과,031-828-2466,2021-09-10'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popList = _my.map(lambda x: x.split()).take(3)\n",
    "popList[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d449c277",
   "metadata": {},
   "source": [
    "# DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eec2e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "popDf = spark\\\n",
    "            .read.option(\"charset\", \"euc-kr\")\\\n",
    "            .option(\"header\", \"true\")\\\n",
    "            .csv(os.path.join(\"data\",\"경기도 의정부시_인구현황_20210910.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ee5a530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------+----------+----------+----------+----------+------+------+----------+----------+----------+------------+--------------+\n",
      "| 행정기관|인구수(계)|인구수(남)|인구수(여)|구성비(계)|구성비(남)|구성비(여)|  성비|세대수|세대당인구|관리기관명|관리부서명|부서전화번호|데이터기준일자|\n",
      "+---------+----------+----------+----------+----------+----------+----------+------+------+----------+----------+----------+------------+--------------+\n",
      "|의정부1동|     32292|     16538|     15754|      6.97|      3.57|       3.4|104.98| 19998|      1.61|  의정부시|민원여권과|031-828-2466|    2021-09-10|\n",
      "|의정부2동|     31380|     15608|     15772|      6.77|      3.37|       3.4| 98.96| 16410|      1.91|  의정부시|민원여권과|031-828-2466|    2021-09-10|\n",
      "|  호원1동|     36124|     17595|     18529|       7.8|       3.8|         4| 94.96| 15653|      2.31|  의정부시|민원여권과|031-828-2466|    2021-09-10|\n",
      "|  호원2동|     34957|     16923|     18034|      7.54|      3.65|      3.89| 93.84| 13683|      2.55|  의정부시|민원여권과|031-828-2466|    2021-09-10|\n",
      "|   장암동|     20314|      9714|     10600|      4.38|       2.1|      2.29| 91.64|  8604|      2.36|  의정부시|민원여권과|031-828-2466|    2021-09-10|\n",
      "+---------+----------+----------+----------+----------+----------+----------+------+------+----------+----------+----------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "popDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb3ebce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "popDf = spark\\\n",
    "            .read.option(\"charset\", \"euc-kr\")\\\n",
    "            .option(\"header\", \"true\")\\\n",
    "            .csv(os.path.join(\"data\",\"제주특별자치도 서귀포시_고령화비율및노령화지수현황_20210831.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ec75f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+----------------+---------------+----------+----------+--------------+\n",
      "|연도별|서귀포시 인구수|65세이상 인구수 |14세이하 인구수|고령화비율|노령화지수|데이터기준일자|\n",
      "+------+---------------+----------------+---------------+----------+----------+--------------+\n",
      "|  2012|         154057|           25826|          22861|     16.76|    112.97|    2021-08-31|\n",
      "|  2013|         155641|           26936|          22393|     17.31|    120.29|    2021-08-31|\n",
      "|  2014|         158512|           27877|          22058|     17.59|    126.38|    2021-08-31|\n",
      "|  2015|         164519|           28979|          22362|     17.61|    129.59|    2021-08-31|\n",
      "|  2016|         170932|           30030|          23044|     17.57|    130.32|    2021-08-31|\n",
      "+------+---------------+----------------+---------------+----------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "popDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9c866a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/ds3_popCsvRead.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/ds3_popCsvRead.py\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: UTF-8 -*-\n",
    "import os\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "\n",
    "def doIt():\n",
    "    print (\"---------RESULT-----------\")\n",
    "    popDf = spark\\\n",
    "                .read.option(\"charset\", \"euc-kr\")\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .csv(os.path.join(\"data\",\"경기도 의정부시_인구현황_20210910.csv\"))\n",
    "    popDf.show(5)\n",
    "    agedDf = spark\\\n",
    "                .read.option(\"charset\", \"euc-kr\")\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .csv(os.path.join(\"data\",\"제주특별자치도 서귀포시_고령화비율및노령화지수현황_20210831.csv\"))\n",
    "    agedDf.show(5)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    myConf=pyspark.SparkConf()\n",
    "    spark = pyspark.sql.SparkSession.builder\\\n",
    "        .master(\"local\")\\\n",
    "        .appName(\"myApp\")\\\n",
    "        .config(conf=myConf)\\\n",
    "        .getOrCreate()\n",
    "    doIt()\n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "323eda44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------RESULT-----------\n",
      "+---------+----------+----------+----------+----------+----------+----------+------+------+----------+----------+----------+------------+--------------+\n",
      "| 행정기관|인구수(계)|인구수(남)|인구수(여)|구성비(계)|구성비(남)|구성비(여)|  성비|세대수|세대당인구|관리기관명|관리부서명|부서전화번호|데이터기준일자|\n",
      "+---------+----------+----------+----------+----------+----------+----------+------+------+----------+----------+----------+------------+--------------+\n",
      "|의정부1동|     32292|     16538|     15754|      6.97|      3.57|       3.4|104.98| 19998|      1.61|  의정부시|민원여권과|031-828-2466|    2021-09-10|\n",
      "|의정부2동|     31380|     15608|     15772|      6.77|      3.37|       3.4| 98.96| 16410|      1.91|  의정부시|민원여권과|031-828-2466|    2021-09-10|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/C:/Spark/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/09/23 14:14:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "21/09/23 14:14:35 INFO SparkContext: Running Spark version 3.1.2"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  호원1동|     36124|     17595|     18529|       7.8|       3.8|         4| 94.96| 15653|      2.31|  의정부시|민원여권과|031-828-2466|    2021-09-10|\n",
      "|  호원2동|     34957|     16923|     18034|      7.54|      3.65|      3.89| 93.84| 13683|      2.55|  의정부시|민원여권과|031-828-2466|    2021-09-10|\n",
      "|   장암동|     20314|      9714|     10600|      4.38|       2.1|      2.29| 91.64|  8604|      2.36|  의정부시|민원여권과|031-828-2466|    2021-09-10|\n",
      "+---------+----------+----------+----------+----------+----------+----------+------+------+----------+----------+----------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+---------------+----------------+---------------+----------+----------+--------------+\n",
      "|연도별|서귀포시 인구수|65세이상 인구수 |14세이하 인구수|고령화비율|노령화지수|데이터기준일자|\n",
      "+------+---------------+----------------+---------------+----------+----------+--------------+\n",
      "|  2012|         154057|           25826|          22861|     16.76|    112.97|    2021-08-31|\n",
      "|  2013|         155641|           26936|          22393|     17.31|    120.29|    2021-08-31|\n",
      "|  2014|         158512|           27877|          22058|     17.59|    126.38|    2021-08-31|\n",
      "|  2015|         164519|           28979|          22362|     17.61|    129.59|    2021-08-31|\n",
      "|  2016|         170932|           30030|          23044|     17.57|    130.32|    2021-08-31|\n",
      "+------+---------------+----------------+---------------+----------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21/09/23 14:14:35 INFO ResourceUtils: ==============================================================\n",
      "21/09/23 14:14:35 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "21/09/23 14:14:35 INFO ResourceUtils: ==============================================================\n",
      "21/09/23 14:14:35 INFO SparkContext: Submitted application: myApp\n",
      "21/09/23 14:14:35 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "21/09/23 14:14:35 INFO ResourceProfile: Limiting resource is cpu\n",
      "21/09/23 14:14:35 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "21/09/23 14:14:35 INFO SecurityManager: Changing view acls to: user\n",
      "21/09/23 14:14:35 INFO SecurityManager: Changing modify acls to: user\n",
      "21/09/23 14:14:35 INFO SecurityManager: Changing view acls groups to: \n",
      "21/09/23 14:14:35 INFO SecurityManager: Changing modify acls groups to: \n",
      "21/09/23 14:14:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(user); groups with view permissions: Set(); users  with modify permissions: Set(user); groups with modify permissions: Set()\n",
      "21/09/23 14:14:36 INFO Utils: Successfully started service 'sparkDriver' on port 1089.\n",
      "21/09/23 14:14:36 INFO SparkEnv: Registering MapOutputTracker\n",
      "21/09/23 14:14:36 INFO SparkEnv: Registering BlockManagerMaster\n",
      "21/09/23 14:14:36 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "21/09/23 14:14:36 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "21/09/23 14:14:36 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "21/09/23 14:14:36 INFO DiskBlockManager: Created local directory at C:\\Users\\user\\AppData\\Local\\Temp\\blockmgr-02c3013c-12bc-44f0-ab3c-f402f10224cc\n",
      "21/09/23 14:14:36 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB\n",
      "21/09/23 14:14:36 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "21/09/23 14:14:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "21/09/23 14:14:36 INFO Utils: Successfully started service 'SparkUI' on port 4041.\n",
      "21/09/23 14:14:36 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.55.202:4041\n",
      "21/09/23 14:14:37 INFO Executor: Starting executor ID driver on host 192.168.55.202\n",
      "21/09/23 14:14:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 1104.\n",
      "21/09/23 14:14:37 INFO NettyBlockTransferService: Server created on 192.168.55.202:1104\n",
      "21/09/23 14:14:37 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "21/09/23 14:14:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.55.202, 1104, None)\n",
      "21/09/23 14:14:37 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.55.202:1104 with 434.4 MiB RAM, BlockManagerId(driver, 192.168.55.202, 1104, None)\n",
      "21/09/23 14:14:37 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.55.202, 1104, None)\n",
      "21/09/23 14:14:37 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.55.202, 1104, None)\n",
      "21/09/23 14:14:37 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/user/Desktop/3-2/Bigdata/201710773/spark-warehouse').\n",
      "21/09/23 14:14:37 INFO SharedState: Warehouse path is 'file:/C:/Users/user/Desktop/3-2/Bigdata/201710773/spark-warehouse'.\n",
      "21/09/23 14:14:38 INFO InMemoryFileIndex: It took 37 ms to list leaf files for 1 paths.\n",
      "21/09/23 14:14:38 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.\n",
      "21/09/23 14:14:40 INFO FileSourceStrategy: Pushed Filters: \n",
      "21/09/23 14:14:40 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "21/09/23 14:14:40 INFO FileSourceStrategy: Output Data Schema: struct<value: string>\n",
      "21/09/23 14:14:40 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 174.9 KiB, free 434.2 MiB)\n",
      "21/09/23 14:14:40 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.7 KiB, free 434.2 MiB)\n",
      "21/09/23 14:14:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.55.202:1104 (size: 27.7 KiB, free: 434.4 MiB)\n",
      "21/09/23 14:14:40 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0\n",
      "21/09/23 14:14:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4195881 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "21/09/23 14:14:41 INFO CodeGenerator: Code generated in 175.8624 ms\n",
      "21/09/23 14:14:41 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0\n",
      "21/09/23 14:14:41 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "21/09/23 14:14:41 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)\n",
      "21/09/23 14:14:41 INFO DAGScheduler: Parents of final stage: List()\n",
      "21/09/23 14:14:41 INFO DAGScheduler: Missing parents: List()\n",
      "21/09/23 14:14:41 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "21/09/23 14:14:41 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.3 KiB, free 434.2 MiB)\n",
      "21/09/23 14:14:41 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 434.2 MiB)\n",
      "21/09/23 14:14:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.55.202:1104 (size: 6.6 KiB, free: 434.4 MiB)\n",
      "21/09/23 14:14:41 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1388\n",
      "21/09/23 14:14:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "21/09/23 14:14:41 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "21/09/23 14:14:41 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.55.202, executor driver, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()\n",
      "21/09/23 14:14:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "21/09/23 14:14:41 INFO FileScanRDD: Reading File path: file:///C:/Users/user/Desktop/3-2/Bigdata/201710773/data/경기도%20의정부시_인구현황_20210910.csv, range: 0-1577, partition values: [empty row]\n",
      "21/09/23 14:14:41 INFO CodeGenerator: Code generated in 8.7607 ms\n",
      "21/09/23 14:14:41 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1727 bytes result sent to driver\n",
      "21/09/23 14:14:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 171 ms on 192.168.55.202 (executor driver) (1/1)\n",
      "21/09/23 14:14:41 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "21/09/23 14:14:41 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 0.290 s\n",
      "21/09/23 14:14:41 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "21/09/23 14:14:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished\n",
      "21/09/23 14:14:41 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 0.321192 s\n",
      "21/09/23 14:14:41 INFO CodeGenerator: Code generated in 7.6174 ms\n",
      "21/09/23 14:14:41 INFO FileSourceStrategy: Pushed Filters: \n",
      "21/09/23 14:14:41 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "21/09/23 14:14:41 INFO FileSourceStrategy: Output Data Schema: struct<행정기관: string, 인구수(계): string, 인구수(남): string, 인구수(여): string, 구성비(계): string ... 12 more fields>\n",
      "21/09/23 14:14:42 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 174.8 KiB, free 434.0 MiB)\n",
      "21/09/23 14:14:42 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 434.0 MiB)\n",
      "21/09/23 14:14:42 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.55.202:1104 (size: 27.6 KiB, free: 434.3 MiB)\n",
      "21/09/23 14:14:42 INFO SparkContext: Created broadcast 2 from showString at NativeMethodAccessorImpl.java:0\n",
      "21/09/23 14:14:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4195881 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "21/09/23 14:14:42 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Got job 1 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Final stage: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0)\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Missing parents: List()\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "21/09/23 14:14:42 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 10.4 KiB, free 434.0 MiB)\n",
      "21/09/23 14:14:42 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.0 MiB)\n",
      "21/09/23 14:14:42 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.55.202:1104 (size: 5.5 KiB, free: 434.3 MiB)\n",
      "21/09/23 14:14:42 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1388\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "21/09/23 14:14:42 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0\n",
      "21/09/23 14:14:42 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (192.168.55.202, executor driver, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()\n",
      "21/09/23 14:14:42 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
      "21/09/23 14:14:42 INFO FileScanRDD: Reading File path: file:///C:/Users/user/Desktop/3-2/Bigdata/201710773/data/경기도%20의정부시_인구현황_20210910.csv, range: 0-1577, partition values: [empty row]\n",
      "21/09/23 14:14:42 INFO CodeGenerator: Code generated in 15.4835 ms\n",
      "21/09/23 14:14:42 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2003 bytes result sent to driver\n",
      "21/09/23 14:14:42 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 52 ms on 192.168.55.202 (executor driver) (1/1)\n",
      "21/09/23 14:14:42 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "21/09/23 14:14:42 INFO DAGScheduler: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 0.061 s\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "21/09/23 14:14:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Job 1 finished: showString at NativeMethodAccessorImpl.java:0, took 0.062448 s\n",
      "21/09/23 14:14:42 INFO CodeGenerator: Code generated in 17.9451 ms\n",
      "21/09/23 14:14:42 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.\n",
      "21/09/23 14:14:42 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "21/09/23 14:14:42 INFO FileSourceStrategy: Pushed Filters: \n",
      "21/09/23 14:14:42 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "21/09/23 14:14:42 INFO FileSourceStrategy: Output Data Schema: struct<value: string>\n",
      "21/09/23 14:14:42 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 174.9 KiB, free 433.8 MiB)\n",
      "21/09/23 14:14:42 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 27.7 KiB, free 433.8 MiB)\n",
      "21/09/23 14:14:42 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.55.202:1104 (size: 27.7 KiB, free: 434.3 MiB)\n",
      "21/09/23 14:14:42 INFO SparkContext: Created broadcast 4 from csv at NativeMethodAccessorImpl.java:0\n",
      "21/09/23 14:14:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194887 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "21/09/23 14:14:42 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Missing parents: List()\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "21/09/23 14:14:42 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 14.3 KiB, free 433.8 MiB)\n",
      "21/09/23 14:14:42 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 433.8 MiB)\n",
      "21/09/23 14:14:42 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.55.202:1104 (size: 6.7 KiB, free: 434.3 MiB)\n",
      "21/09/23 14:14:42 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1388\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "21/09/23 14:14:42 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0\n",
      "21/09/23 14:14:42 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (192.168.55.202, executor driver, partition 0, PROCESS_LOCAL, 4971 bytes) taskResourceAssignments Map()\n",
      "21/09/23 14:14:42 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)\n",
      "21/09/23 14:14:42 INFO FileScanRDD: Reading File path: file:///C:/Users/user/Desktop/3-2/Bigdata/201710773/data/제주특별자치도%20서귀포시_고령화비율및노령화지수현황_20210831.csv, range: 0-583, partition values: [empty row]\n",
      "21/09/23 14:14:42 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1609 bytes result sent to driver\n",
      "21/09/23 14:14:42 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 12 ms on 192.168.55.202 (executor driver) (1/1)\n",
      "21/09/23 14:14:42 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "21/09/23 14:14:42 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.020 s\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "21/09/23 14:14:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.022782 s\n",
      "21/09/23 14:14:42 INFO FileSourceStrategy: Pushed Filters: \n",
      "21/09/23 14:14:42 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "21/09/23 14:14:42 INFO FileSourceStrategy: Output Data Schema: struct<연도별: string, 서귀포시 인구수: string, 65세이상 인구수 : string, 14세이하 인구수: string, 고령화비율: string ... 5 more fields>\n",
      "21/09/23 14:14:42 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 174.8 KiB, free 433.6 MiB)\n",
      "21/09/23 14:14:42 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 433.6 MiB)\n",
      "21/09/23 14:14:42 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.55.202:1104 (size: 27.6 KiB, free: 434.3 MiB)\n",
      "21/09/23 14:14:42 INFO SparkContext: Created broadcast 6 from showString at NativeMethodAccessorImpl.java:0\n",
      "21/09/23 14:14:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194887 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "21/09/23 14:14:42 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Got job 3 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Final stage: ResultStage 3 (showString at NativeMethodAccessorImpl.java:0)\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Missing parents: List()\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[27] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "21/09/23 14:14:42 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 9.7 KiB, free 433.5 MiB)\n",
      "21/09/23 14:14:42 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 433.5 MiB)\n",
      "21/09/23 14:14:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.55.202:1104 (size: 5.3 KiB, free: 434.3 MiB)\n",
      "21/09/23 14:14:42 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1388\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[27] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "21/09/23 14:14:42 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0\n",
      "21/09/23 14:14:42 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (192.168.55.202, executor driver, partition 0, PROCESS_LOCAL, 4971 bytes) taskResourceAssignments Map()\n",
      "21/09/23 14:14:42 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)\n",
      "21/09/23 14:14:42 INFO FileScanRDD: Reading File path: file:///C:/Users/user/Desktop/3-2/Bigdata/201710773/data/제주특별자치도%20서귀포시_고령화비율및노령화지수현황_20210831.csv, range: 0-583, partition values: [empty row]\n",
      "21/09/23 14:14:42 INFO CodeGenerator: Code generated in 9.7527 ms\n",
      "21/09/23 14:14:42 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1647 bytes result sent to driver\n",
      "21/09/23 14:14:42 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 24 ms on 192.168.55.202 (executor driver) (1/1)\n",
      "21/09/23 14:14:42 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool \n",
      "21/09/23 14:14:42 INFO DAGScheduler: ResultStage 3 (showString at NativeMethodAccessorImpl.java:0) finished in 0.031 s\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "21/09/23 14:14:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished\n",
      "21/09/23 14:14:42 INFO DAGScheduler: Job 3 finished: showString at NativeMethodAccessorImpl.java:0, took 0.034545 s\n",
      "21/09/23 14:14:42 INFO CodeGenerator: Code generated in 10.2101 ms\n",
      "21/09/23 14:14:42 INFO SparkUI: Stopped Spark web UI at http://192.168.55.202:4041\n",
      "21/09/23 14:14:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "21/09/23 14:14:42 INFO MemoryStore: MemoryStore cleared\n",
      "21/09/23 14:14:42 INFO BlockManager: BlockManager stopped\n",
      "21/09/23 14:14:42 INFO BlockManagerMaster: BlockManagerMaster stopped\n",
      "21/09/23 14:14:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "21/09/23 14:14:42 INFO SparkContext: Successfully stopped SparkContext\n",
      "21/09/23 14:14:42 INFO ShutdownHookManager: Shutdown hook called\n",
      "21/09/23 14:14:42 INFO ShutdownHookManager: Deleting directory C:\\Users\\user\\AppData\\Local\\Temp\\spark-d14ea587-2f98-4f6d-8327-4570fa4c6a6d\\pyspark-85e45473-61f3-482e-8b4b-1ac90b102b59\n",
      "21/09/23 14:14:42 INFO ShutdownHookManager: Deleting directory C:\\Users\\user\\AppData\\Local\\Temp\\spark-d14ea587-2f98-4f6d-8327-4570fa4c6a6d\n",
      "21/09/23 14:14:42 INFO ShutdownHookManager: Deleting directory C:\\Users\\user\\AppData\\Local\\Temp\\spark-888d1177-74fa-4d51-abbe-e8f41ce4070f\n"
     ]
    }
   ],
   "source": [
    "!spark-submit src/ds3_popCsvRead.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebbbbb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
